# Neural-Network-from-Scratch

Project Overview
In this project, we will walk through the theory behind neural networks and build one from scratch using Python and NumPy. We will focus on the key components of neural networks, including the forward pass, loss functions, backpropagation, gradient descent, and the training loop. By the end of this project, we will apply our neural network to predict the precipitation levels in New Jersey through the months of September to November.

Key Concepts Covered
Forward Pass: Understanding how data flows through the layers of the network.
Loss Functions: How to measure the difference between predicted and actual values.
Backward Pass (Backpropagation): Using the chain rule to adjust weights and minimize the error.
Gradient Descent: An optimization technique to adjust weights based on the gradients of the loss function.
Training Loop: The iterative process of training the network by passing data through the network, calculating the loss, and adjusting the weights.

Project Goals
Build a multi-layer neural network from scratch using NumPy.
Implement the forward pass, loss functions, backpropagation, and gradient descent.
Train the network to predict precipitation levels in New Jersey for the months of September-November.
Understand and apply machine learning concepts through hands-on implementation.
